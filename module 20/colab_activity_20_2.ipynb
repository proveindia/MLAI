{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d164420705a4fece",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Colab Activity 20.2: Implementing the AdaBoost Algorithm\n",
    "\n",
    "**Time: 60 minutes**\n",
    "\n",
    "This activity focuses on using the `AdaBoostClassifier` and the performance resulting from changing the base classifier that is used.  As discussed in the lectures, adaptive boosting is a successive reweighting of data using a set number of estimators.  These weighted estimators are what form the ensemble, and the predictions are a result of a weighted combination of the estimators.  \n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fetal.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fetal_health', axis = 1).values\n",
    "y = df['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6037217b547e73a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### `AdaBoostClassifier`\n",
    "\n",
    "\n",
    "Instantiate an `AdaBoostClassifier` estimator with `max_depth=1` and assign it to `ans1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-610a6433eeb011fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ans1 = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "ans1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9374e15cda778d0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Fitting the Ensemble\n",
    "\n",
    "\n",
    "\n",
    "Define an `AdaBoostClassifier` estimator with default parameters and to fit to the data `X_train` and `y_train`. Assign this model to `model_1` below.\n",
    "\n",
    "Assign the accuracy of the model on the test data to `model_1_acc` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92ed88043191a639",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881578947368421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = AdaBoostClassifier().fit(X_train, y_train)\n",
    "model_1_acc = model_1.score(X_test, y_test)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model_1_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-905335749b0f9e64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Grid Searching the Ensemble\n",
    "\n",
    "\n",
    "As the documentation states [on this page](https://scikit-learn.org/stable/modules/ensemble.html#usage), the main parameters to search are the number of estimators and the complexity of the base estimator.  \n",
    "\n",
    "In the code cell below, create a parameter grid that considers the following parameters:\n",
    "\n",
    "- *number of estimators*: 100, 200\n",
    "- *max_depths*: 1, 2, 3\n",
    "\n",
    "Name this grid `params`.\n",
    "\n",
    "Next, use the grid `params` with the `AdaBoostClassifier` to perform a grid search named `tree_grid` on the train data.  For this step, be sure to set the `random_state = 42` in your `AdaBoostClassifier`. \n",
    "\n",
    "Finally, calculate the score on the test data as `grid_acc`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0510fdbbf90c3779",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'n_estimators': [100, 200],\n",
    "         'base_estimator__max_depth': [1, 2, 3]}\n",
    "tree_grid = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state = 42), \n",
    "                         param_grid=params).fit(X_train, y_train)\n",
    "grid_acc = tree_grid.score(X_test, y_test)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(grid_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8aa3fa345d098088",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### A Different Base Estimator\n",
    "\n",
    "\n",
    "\n",
    "Consider using a different base estimator such as `LogisticRegression` estimator.  Explore the neighbors parameters with \n",
    "\n",
    "- `C = [.001, 0.01, 0.1, 1.0, 10.0]`\n",
    "\n",
    "Create a `Pipeline` that scales the data first and then implements an `AdaBoostClassifier` with `random_state = 42` and a Logistic Regression model.  Grid search the pipeline with a grid and assign the score on the test data to `score2`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bbf690915a58f45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'mod__base_estimator__C': [.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "p = Pipeline([('scale', StandardScaler()),\n",
    "             ('mod', AdaBoostClassifier(base_estimator = LogisticRegression(), \n",
    "                                       random_state = 42))\n",
    "             ])\n",
    "g = GridSearchCV(p,\n",
    "                param_grid=params)\n",
    "g.fit(X_train, y_train)\n",
    "score2 = g.score(X_test, y_test)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(score2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db5a64b691d49358",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Evaluating the models\n",
    "\n",
    "\n",
    "Which model performed the best on the test data?\n",
    "\n",
    "- `a`: Base `AdaBoostClassifier`\n",
    "- `b`: Grid Searched Tree Model\n",
    "- `c`: Grid Searched Logistic Model\n",
    "- `d`: None of the above\n",
    "\n",
    "Assign your answer as a string to `ans5` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12e99140e358ffcc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ans5 = 'b'\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
