{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a2fb5123ae5c455",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Colab activity 13.2: Decision Boundaries with Two Variable\n",
    "\n",
    "**Expected Time = 60 minutes** \n",
    " \n",
    "\n",
    "In the first examples, your work has utilized a straight vertical line as the decision boundary for logistic regression. This is what a decision boundary looks like with only one feature, however with two features the decision boundary becomes a linear function of the two inputs. In this activity, you will focus on generating functions for these boundaries and show strategies for visualizing these boundaries. \n",
    "\n",
    "#### Index\n",
    "\n",
    "  - [Problem 1](#-Problem-1)\n",
    "  - [Problem 2](#-Problem-2)\n",
    "  - [Problem 3](#-Problem-3)\n",
    "  - [Problem 4](#-Problem-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-180308aae7d2d7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Again, you will use the penguins data from Seaborn.  This time, you will use two features -- `flipper_length_mm` and `bill_length_mm` to build a logistic model and visualize the decision boundary.  The data is loaded and visualized below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins').dropna()\n",
    "penguins = penguins.loc[(penguins['species'] == 'Adelie') | (penguins['species'] == 'Gentoo')]\n",
    "X = penguins.drop('species', axis = 1)[['flipper_length_mm', 'bill_length_mm']]\n",
    "y = np.where(penguins.species == 'Adelie', 0, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = penguins, x = 'flipper_length_mm', y = 'bill_length_mm', hue = 'species')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61ccd016c98fc188",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### A Logistic Model\n",
    "\n",
    "\n",
    "Instantiate a `LogisticRegression` estimator as `log_reg` below and fit on the training data `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a9e2edd23d53626",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(log_reg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e0354e412867e85",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Examining the coefficients\n",
    "\n",
    "\n",
    "\n",
    "With two variables, the Sigma function is given by:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-z}},$$\n",
    "\n",
    "where\n",
    "\n",
    "$$z = \\beta_0 + \\beta_1 * x_0 + \\beta_2 * x_1.$$\n",
    "\n",
    "Below, assign the intercept to  `beta_0` and the  coefficients to `beta_1` and `beta_2`, respectively.\n",
    "\n",
    "Note that $x_0$ is the flipper length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de41271c6395179d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "beta_0 = float(log_reg.intercept_)\n",
    "beta_1 = float(log_reg.coef_[0][0])\n",
    "beta_2 = float(log_reg.coef_[0][1])\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(f'z = {beta_0: .2f} + {beta_1: .2f}x0 + {beta_2: .2f}x1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81c77c9e7339f736",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Visualizing the decision boundary\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img src = 'images/dboundary.png' />\n",
    "</center>\n",
    "\n",
    "\n",
    "There is both a brute force and more formal approach for visualizing the decision boundary. \n",
    "\n",
    "With two variables we can directly solve for the linear function in terms of `x_0` and  `beta`'s. Upon doing so we find a linear function defined as: \n",
    "\n",
    "$$y = -\\frac{\\beta_1}{\\beta_2} * x_0 - \\frac{\\beta_0}{\\beta_2}$$\n",
    "\n",
    "Complete the function `decision_boundary` below that takes in `x_0` and  `beta`'s. This function should return the appropriate value for the predicitons based on the formula above.  Uncomment the plot to verify your results using the defined `x = np.linspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e6d6568117a8e6b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def decision_boundary(x0, beta_0, beta_1, beta_2):\n",
    "    return -(beta_1/beta_2)*x0 - beta_0/beta_2\n",
    "\n",
    "\n",
    "# Answer check\n",
    "x = np.linspace(165, 240, 100)\n",
    "print(decision_boundary(x, beta_0, beta_1, beta_2)[0], decision_boundary(x, beta_0, beta_1, beta_2)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code for figure\n",
    "x = np.linspace(165, 240, 100)\n",
    "sns.scatterplot(data = penguins, x = 'flipper_length_mm', y = 'bill_length_mm', hue = 'species')\n",
    "plt.plot(x, decision_boundary(x, beta_0, beta_1, beta_2), '--', color = 'black')\n",
    "plt.ylim(25, 65)\n",
    "plt.fill_between(x, decision_boundary(x, beta_0, beta_1, beta_2), alpha = 0.3, color = 'lightblue')\n",
    "plt.fill_between(x, decision_boundary(x, beta_0, beta_1, beta_2), np.repeat(70, 100), alpha = 0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-769e80a3f0f16a66",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Comparing regressors\n",
    "\n",
    "\n",
    "Now, fit a second regressor using the argument `C = 0.001`. Compare the decision boundary by using what you've seen earlier. How did the decision boundary change based on this?  The slope of the new decision boundary should either be greater than or less than the default settings. Assign your answer as a string -- `greater than` or `less than` -- to `ans4` below. Hint: Remember that the slope is negative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66dfc51fc45c7a0f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ans4 = 'less than'\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
