# Module 19: Collaborative Filtering and Recommendation Systems

## Overview
This module explored Recommendation Systems, focusing on Collaborative Filtering and the use of the `Surprise` library to predict user ratings.

## Key Concepts
*   **Collaborative Filtering:** Making predictions about the interests of a user by collecting preferences from many users.
*   **Latent Features:** Hidden features that explain the relationship between users and items.
*   **Alternating Least Squares (ALS):** Iterative optimization to find user and item factors.
*   **Matrix Factorization (SVD):** Decomposing the user-item interaction matrix into lower-dimensional matrices.
*   **Surprise Library:** A Python scikit for building and analyzing recommender systems.
*   **Hybrid Recommendations:** Combining multiple algorithms (e.g., SVD + SlopeOne) to improve prediction accuracy.

## Key Formulas

### 1. Matrix Factorization (ALS Update Rule)
For Alternating Least Squares (ALS), the user factors $P$ are updated iteratively to minimize the error between predicted and actual ratings.

$$P_{a,b} := P_{a,b} - \alpha \sum_{j \in R_a}^N e_{a,j}Q_{b,j}$$

*   $P_{a,b}$: User factor matrix value.
*   $\alpha$: Learning rate.
*   $e_{a,j}$: Error term (difference between actual and predicted rating).
*   $Q_{b,j}$: Item factor matrix value.

### 2. Weighted Hybrid Prediction
A weighted hybrid model combines predictions from multiple algorithms (e.g., SVD and SlopeOne) using a linear combination.

$$\hat{r}_{ui} = \alpha \cdot \hat{r}_{SVD} + (1-\alpha) \cdot \hat{r}_{SlopeOne}$$

In the assignment, an equal weight ($\alpha = 0.5$) was used:
$$ \hat{r}_{hybrid} = 0.5 \cdot \hat{r}_{SVD} + 0.5 \cdot \hat{r}_{SlopeOne} $$

### 3. Similarity Measures (KNN)
Memory-based collaborative filtering relies on similarity measures like Cosine Similarity or Pearson Correlation.

**Cosine Similarity:**
$$ \text{sim}(u, v) = \frac{\sum_{i} r_{ui} r_{vi}}{\sqrt{\sum_{i} r_{ui}^2} \sqrt{\sum_{i} r_{vi}^2}} $$

## Types of Hybrid Recommendation

While the module focused on **Weighted Hybrid**, there are several types of hybrid recommendation systems:

1.  **Weighted:** The scores of several recommendation techniques are combined together numerically (e.g., Linear Combination).
2.  **Switching:** The system switches between recommendation techniques depending on the heuristic or criteria (e.g., use Content-based if user profile is new, otherwise CF).
3.  **Mixed:** Recommendations from different referrers are presented together (e.g., "People who bought X also bought Y" next to "Recommended for you").
4.  **Feature Combination:** Features from different data sources are thrown together into a single recommendation algorithm.
5.  **Cascade:** One recommender refines the recommendations given by another.
6.  **Feature Augmentation:** Output from one technique is used as an input feature to another.
7.  **Meta-level:** The model generated by one recommender is used as the input for another.

## Implementation Details

### 1. Manual Collaborative Filtering (ALS)
We manually implemented an ALS approach using Linear Regression.
```python
# Iteratively solving for User and Item coefficients
lr = LinearRegression(fit_intercept=False).fit(X, y)
coefs = lr.coef_
```

### 2. Using the Surprise Library
We used `surpriselib` to streamline the recommendation process.

**Loading Data:**
```python
from surprise import Dataset, Reader
reader = Reader(rating_scale=(0, 5))
data = Dataset.load_from_df(df[['userId', 'title', 'rating']], reader)
train = data.build_full_trainset()
```

**SVD Model:**
```python
from surprise import SVD
model = SVD(n_factors=2, random_state=42)
model.fit(train)
test = train.build_testset()
predictions = model.test(test)
```

**SlopeOne Model:**
```python
from surprise import SlopeOne
slope_one = SlopeOne()
slope_one.fit(train)
slope_one_preds = slope_one.test(test)
```

**Hybrid Predictions:**
Combining predictions from SVD and SlopeOne can often yield better results.
```python
hybrid_preds = [0.5 * i.est + 0.5 * j.est for i, j in zip(slope_one_preds, svd_preds)]
```

**Cross Validation:**
Evaluating model performance using RMSE.
```python
from surprise.model_selection import cross_validate
cross_validate(model, data, measures=['RMSE'], cv=5)
```

## Assignment Highlights
*   **Data:** User ratings for artists/albums and MovieLens dataset.
*   **Goal:** Predict missing ratings for users.
*   **Process:**
    *   Implemented manual Matrix Factorization using `LinearRegression`.
    *   Utilized the `Surprise` library for standard algorithms like `SVD` and `SlopeOne`.
    *   Created a hybrid model by averaging predictions from different algorithms.
