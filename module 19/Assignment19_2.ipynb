{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01541d3406dd9f09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Required Assignment 19.2: Using SURPRISE\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 50**\n",
    "\n",
    "This activity focuses on using the `Surprise` library to predict user ratings.  You will use a dataset derived from the movieLens data -- a common benchmark for recommendation algorithms.  Using `Surprise` you will load the data, create a train set and test set, make predictions for a test set, and cross validate the model on the dataset. \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-730589da841883ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The data is derived from the MovieLens data [here](https://grouplens.org/datasets/movielens/).  The original dataset has been sampled so the processing is faster.\n",
    "\n",
    "The dataframe contain information about the user, movie, and the associated ratings when they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = pd.read_csv('data/movie_ratings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a17048648f3308a5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Loading a Dataset\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Extract the columns `userId`, `title`, and `rating` from the `movie_ratings` dataframe and assign them to the variable `a`.\n",
    "\n",
    "Initialize a `Reader` object, specifying that the ratings are on a scale from 0 to 5 and assign this result to `reader `. Next, use the `Dataset` object to convert the selected dataframe `a` into the format expected by `Surprise` using the `reader` object. Assign this result to `sf`.\n",
    "\n",
    "Finally, use the `build_full_trainset` function on `sf` to build the full training set from the dataset, making it ready for training a recommendation algorithm. Assign this result to `train`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88a5589687e93534",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "reader = ''\n",
    "sf = ''\n",
    "train = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "a = movie_ratings[['userId', 'title', 'rating']]\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "sf = Dataset.load_from_df(a, reader)\n",
    "train = sf.build_full_trainset()\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(sf))\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6338726abdeb7bdc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Instantiate the `SVD` model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, create an `SVD` object with 2 factors and assign it as `model` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-539585e274da7e26",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "model = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model = SVD(n_factors = 2)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.n_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10c839e82855e0b5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "### Fitting the Model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, fit `model` on the training data `train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc61843ec01be8b7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "#fit your model below. No variable needs to be assigned.\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model.fit(train)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71f4683f25c69ae1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Use the `build_testset` function on `train` to build a testset named `test`. Next, use `test` to create a list of predictions for the testset.  Assign the result to `predictions_list` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b56bdc17f7c3fa17",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "test = ''\n",
    "predictions_list = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "test = train.build_testset()\n",
    "predictions_list = model.test(test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(predictions_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e67cf4a03b206880",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Cross Validate the Model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "You may use the test data to evaluate the model, as well as also cross validate the model using the data object `sf`. \n",
    "\n",
    "In the code cell below, use the `cross_validate` function to calculate the RMSE of the model. Assign the result to `cross_val_results` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8be85aaecf4c78cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "cross_val_results = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "cross_val_results = cross_validate(model, sf, measures=['RMSE'])\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(cross_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
